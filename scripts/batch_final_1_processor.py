#!/usr/bin/env python3
"""
Batch Final 1 - Exames Laboratoriais Parte A (45 items)
Processador MFI com geraÃ§Ã£o de SQL Ãºnico para execuÃ§Ã£o via Docker
"""

import anthropic
import json
import os
import sys
from datetime import datetime

# ConfiguraÃ§Ã£o
API_KEY = os.getenv("ANTHROPIC_API_KEY")
if not API_KEY:
    print("âŒ ANTHROPIC_API_KEY nÃ£o configurada")
    sys.exit(1)

client = anthropic.Anthropic(api_key=API_KEY)

# Carregar dados
with open("/home/user/plenya/scripts/enrichment_data/batch_final_1_exames_A.json", "r", encoding="utf-8") as f:
    data = json.load(f)

print(f"ðŸŽ¯ BATCH FINAL 1 - EXAMES LABORATORIAIS PARTE A")
print(f"ðŸ“Š Total de items: {data['total']}")
print(f"ðŸ¥ Grupo: {data['group']}")
print(f"â° InÃ­cio: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# System prompt MFI
SYSTEM_PROMPT = """VocÃª Ã© um especialista em Medicina Laboratorial Funcional Integrativa (MFI).

**CONTEXTO:** Sistema de prontuÃ¡rio eletrÃ´nico com score items para avaliaÃ§Ã£o de saÃºde.

**PADRÃƒO MFI OBRIGATÃ“RIO:**

1. **Valores Ã“timos Funcionais:** NÃ£o apenas "normal", mas faixas Ã³timas para longevidade
2. **InterpretaÃ§Ã£o Funcional:** Significado clÃ­nico dos valores alterados
3. **Condutas EspecÃ­ficas:** IntervenÃ§Ãµes com doses exatas (suplementos, dieta, exercÃ­cio)
4. **Artigos CientÃ­ficos:** MÃ­nimo 3 referÃªncias PubMed/journals relevantes

**FORMATO DE RESPOSTA (JSON):**

```json
{
  "interpretation": "InterpretaÃ§Ã£o funcional detalhada com faixas Ã³timas. Ex: 'Valores Ã³timos: 50-100 ng/mL (nÃ£o apenas >30). Valores <50 indicam deficiÃªncia subclÃ­nica...'",
  "low_level_description": "ConsequÃªncias de valores baixos com mecanismos fisiopatolÃ³gicos",
  "medium_level_description": "Estado intermediÃ¡rio e riscos associados",
  "high_level_description": "ConsequÃªncias de valores elevados e aÃ§Ãµes necessÃ¡rias",
  "low_level_recommendation": "Condutas especÃ­ficas: suplementaÃ§Ã£o (doses), dieta (alimentos), exercÃ­cio (tipo/intensidade)",
  "medium_level_recommendation": "Ajustes para otimizaÃ§Ã£o funcional",
  "high_level_recommendation": "IntervenÃ§Ãµes para normalizaÃ§Ã£o com follow-up",
  "articles": [
    {
      "title": "TÃ­tulo completo do artigo",
      "url": "https://pubmed.ncbi.nlm.nih.gov/PMID ou DOI"
    }
  ]
}
```

**EXIGÃŠNCIAS:**
- Interpretation: mÃ­nimo 200 caracteres
- Descriptions: mÃ­nimo 150 caracteres cada
- Recommendations: condutas especÃ­ficas com doses/protocolos
- Artigos: 3-5 referÃªncias vÃ¡lidas (PubMed preferencial)

**ADAPTAR PARA TIPO DE EXAME:**
- Exames de Imagem: interpretar scores/medidas, relaÃ§Ã£o com desfechos clÃ­nicos
- Exames Laboratoriais: valores Ã³timos, nÃ£o apenas referÃªncia laboratorial
- Exames com faixas etÃ¡rias/gÃªnero: especificar contexto na interpretaÃ§Ã£o
"""

# Processar todos os items
results = []
sql_statements = []

for idx, item in enumerate(data["items"], 1):
    print(f"\n{'='*80}")
    print(f"[{idx}/{data['total']}] Processando: {item['name']}")
    print(f"ID: {item['id']}")
    print(f"Subgrupo: {item['subgroup']}")

    try:
        # Chamar Claude
        message = client.messages.create(
            model="claude-opus-4-5-20251101",
            max_tokens=4000,
            temperature=1,
            system=SYSTEM_PROMPT,
            messages=[{
                "role": "user",
                "content": f"""EnriqueÃ§a este score item com padrÃ£o MFI:

**Nome:** {item['name']}
**Subgrupo:** {item['subgroup']}
**Contexto:** Exame {'de imagem' if item['subgroup'] == 'Imagem' else 'laboratorial'}

Retorne APENAS o JSON conforme especificado no system prompt."""
            }]
        )

        # Parse resposta
        content = message.content[0].text.strip()

        # Limpar markdown se presente
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        elif content.startswith("```"):
            content = content.replace("```", "").strip()

        enrichment = json.loads(content)

        # ValidaÃ§Ã£o
        required_fields = [
            "interpretation", "low_level_description", "medium_level_description",
            "high_level_description", "low_level_recommendation",
            "medium_level_recommendation", "high_level_recommendation", "articles"
        ]

        missing = [f for f in required_fields if f not in enrichment or not enrichment[f]]
        if missing:
            print(f"âš ï¸  Campos faltando: {missing}")
            continue

        # Validar tamanho mÃ­nimo
        if len(enrichment["interpretation"]) < 200:
            print(f"âš ï¸  Interpretation muito curto: {len(enrichment['interpretation'])} chars")
            continue

        # Validar artigos
        if len(enrichment["articles"]) < 3:
            print(f"âš ï¸  Apenas {len(enrichment['articles'])} artigos (mÃ­nimo 3)")
            continue

        # Gerar SQL
        articles_json = json.dumps(enrichment["articles"], ensure_ascii=False).replace("'", "''")

        sql = f"""
-- {item['name']} ({item['id']})
UPDATE score_items SET
  interpretation = '{enrichment['interpretation'].replace("'", "''")}',
  low_level_description = '{enrichment['low_level_description'].replace("'", "''")}',
  medium_level_description = '{enrichment['medium_level_description'].replace("'", "''")}',
  high_level_description = '{enrichment['high_level_description'].replace("'", "''")}',
  low_level_recommendation = '{enrichment['low_level_recommendation'].replace("'", "''")}',
  medium_level_recommendation = '{enrichment['medium_level_recommendation'].replace("'", "''")}',
  high_level_recommendation = '{enrichment['high_level_recommendation'].replace("'", "''")}',
  articles = '{articles_json}'::jsonb,
  last_review = NOW()
WHERE id = '{item['id']}';
"""

        sql_statements.append(sql)

        # Resultado
        result = {
            "id": item["id"],
            "name": item["name"],
            "subgroup": item["subgroup"],
            "enrichment": enrichment,
            "status": "success",
            "chars": {
                "interpretation": len(enrichment["interpretation"]),
                "low_desc": len(enrichment["low_level_description"]),
                "medium_desc": len(enrichment["medium_level_description"]),
                "high_desc": len(enrichment["high_level_description"]),
                "low_rec": len(enrichment["low_level_recommendation"]),
                "medium_rec": len(enrichment["medium_level_recommendation"]),
                "high_rec": len(enrichment["high_level_recommendation"])
            },
            "articles_count": len(enrichment["articles"])
        }

        results.append(result)

        print(f"âœ… Enriquecido com sucesso")
        print(f"   Interpretation: {result['chars']['interpretation']} chars")
        print(f"   Artigos: {result['articles_count']}")

    except Exception as e:
        print(f"âŒ Erro: {str(e)}")
        results.append({
            "id": item["id"],
            "name": item["name"],
            "status": "error",
            "error": str(e)
        })
        continue

# Gerar SQL final
print(f"\n{'='*80}")
print(f"ðŸ“ GERANDO SQL ÃšNICO PARA EXECUÃ‡ÃƒO")

sql_file = "/home/user/plenya/batch_final_1_exames_A.sql"
with open(sql_file, "w", encoding="utf-8") as f:
    f.write("-- BATCH FINAL 1 - EXAMES LABORATORIAIS PARTE A\n")
    f.write(f"-- Gerado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"-- Total de items: {len(sql_statements)}/{data['total']}\n\n")
    f.write("BEGIN;\n\n")
    f.write("\n".join(sql_statements))
    f.write("\n\nCOMMIT;\n")

print(f"âœ… SQL gerado: {sql_file}")

# Salvar resultados JSON
results_file = "/home/user/plenya/batch_final_1_exames_A_results.json"
with open(results_file, "w", encoding="utf-8") as f:
    json.dump({
        "batch": "final_1_exames_A",
        "generated_at": datetime.now().isoformat(),
        "total_items": data["total"],
        "processed": len(results),
        "successful": len([r for r in results if r.get("status") == "success"]),
        "failed": len([r for r in results if r.get("status") == "error"]),
        "results": results
    }, f, indent=2, ensure_ascii=False)

print(f"âœ… Resultados salvos: {results_file}")

# EstatÃ­sticas finais
successful = [r for r in results if r.get("status") == "success"]
failed = [r for r in results if r.get("status") == "error"]

print(f"\n{'='*80}")
print(f"ðŸ“Š ESTATÃSTICAS FINAIS")
print(f"âœ… Sucesso: {len(successful)}/{data['total']}")
print(f"âŒ Falhas: {len(failed)}/{data['total']}")

if successful:
    avg_chars = {
        "interpretation": sum(r["chars"]["interpretation"] for r in successful) / len(successful),
        "descriptions": sum(r["chars"]["low_desc"] + r["chars"]["medium_desc"] + r["chars"]["high_desc"] for r in successful) / len(successful) / 3,
        "recommendations": sum(r["chars"]["low_rec"] + r["chars"]["medium_rec"] + r["chars"]["high_rec"] for r in successful) / len(successful) / 3
    }
    avg_articles = sum(r["articles_count"] for r in successful) / len(successful)

    print(f"\nðŸ“ˆ MÃ©dias:")
    print(f"   Interpretation: {avg_chars['interpretation']:.0f} chars")
    print(f"   Descriptions: {avg_chars['descriptions']:.0f} chars")
    print(f"   Recommendations: {avg_chars['recommendations']:.0f} chars")
    print(f"   Artigos: {avg_articles:.1f}")

if failed:
    print(f"\nâš ï¸  Items com falha:")
    for r in failed:
        print(f"   - {r['name']}: {r.get('error', 'Unknown')}")

print(f"\nâ° Fim: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"\nðŸŽ¯ PRÃ“XIMO PASSO: Executar SQL via Docker")
print(f"   docker compose exec db psql -U plenya_user -d plenya_db -f /tmp/batch_final_1_exames_A.sql")
