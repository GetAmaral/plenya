# Plano de Melhoria: Sistema de Preparation (ScoreItem Enrichment)

## üìä An√°lise do Estado Atual

### Estat√≠sticas Gerais
- **Cobertura:** 878/878 ScoreItems (100%) ‚úÖ
- **Avg chunks por preparation:** 13.0
- **Range:** 1-30 chunks

### üî¥ Problemas Cr√≠ticos Identificados

| Problema | Qtd | % | Impacto |
|----------|-----|---|---------|
| **Apenas 1 chunk** | 103 | 11.7% | Contexto cient√≠fico INSUFICIENTE para enrichment |
| **< 10 chunks** | 376 | 42.8% | Contexto FRACO - enrichment limitado |
| **No limite (20 ou 30)** | 401 | 45.7% | Poderiam ter MAIS chunks dispon√≠veis |

### Distribui√ß√£o Atual

```
Chunks por Preparation:
  1 chunk:        103 (11.7%) ‚ùå MUITO FRACO
  2-5 chunks:     197 (22.4%) ‚ùå FRACO
  6-15 chunks:    177 (20.2%) ‚ö†Ô∏è  RAZO√ÅVEL
  16-25 chunks:   367 (41.8%) ‚úÖ BOM
  26-30 chunks:    34 (3.9%)  ‚úÖ EXCELENTE
```

### Par√¢metros Atuais (Problem√°ticos)

```go
// prepare-all/main.go linha 49
prepService.PrepareChunks(item.ID, 30, 0.3)
//                                 ^^  ^^^
//                          limite  threshold FIXO
```

**Problemas:**
1. **Threshold 0.3 fixo** - muito alto para items gen√©ricos
2. **Limite 30** - muito baixo (poderia ser 40-50)
3. **Sem fallback** - se n√£o encontrar chunks com 0.3, desiste
4. **Sem re-preparation** - ignora items que j√° t√™m preparation (mesmo que fraca)

---

## üéØ Proposta de Melhorias

### Melhoria 1: Threshold Adaptativo com Fallback (CR√çTICO)

**Problema:** 42.8% t√™m < 10 chunks porque threshold 0.3 √© muito alto.

**Solu√ß√£o:** Tentativas progressivas at√© atingir 15+ chunks

```go
func prepareWithAdaptiveThreshold(scoreItemID uuid.UUID) {
    targetChunks := 20  // Alvo m√≠nimo
    maxLimit := 50      // Limite m√°ximo

    // Tentativa 1: Threshold normal (0.3)
    chunks := FindTopChunks(scoreItemID, maxLimit, 0.3)

    if len(chunks) >= targetChunks {
        return chunks[:min(30, len(chunks))]  // Sucesso
    }

    // Tentativa 2: Threshold permissivo (0.25)
    chunks = FindTopChunks(scoreItemID, maxLimit, 0.25)

    if len(chunks) >= targetChunks {
        return chunks[:min(30, len(chunks))]
    }

    // Tentativa 3: Threshold muito permissivo (0.2)
    chunks = FindTopChunks(scoreItemID, maxLimit, 0.2)

    if len(chunks) >= targetChunks {
        return chunks[:min(35, len(chunks))]  // Mais chunks se threshold baixo
    }

    // Tentativa 4: Fallback extremo (0.15)
    chunks = FindTopChunks(scoreItemID, maxLimit, 0.15)

    return chunks[:min(40, len(chunks))]  // Retorna o que encontrar
}
```

**Resultado esperado:**
- Preparations fracas (< 10): 42.8% ‚Üí < 5%
- Avg chunks: 13 ‚Üí 22-25
- Preparations com 1 chunk: 11.7% ‚Üí 0%

---

### Melhoria 2: Re-Prepare Items Fracos

**Problema:** 376 preparations t√™m < 10 chunks (insuficiente para enrichment).

**Solu√ß√£o:** Comando para re-preparar apenas os fracos

```bash
# Novo comando: re-prepare-weak/main.go
docker compose exec api go run /app/cmd/re-prepare-weak/main.go

# Estrat√©gia:
# 1. Selecionar preparations com < 15 chunks
# 2. DELETE preparation antiga
# 3. Re-preparar com threshold adaptativo (0.25 ‚Üí 0.2 ‚Üí 0.15)
# 4. Validar que tem >= 15 chunks ou abortar
```

**Verifica√ß√£o:**
```sql
SELECT
    COUNT(*) FILTER (WHERE (metadata->>'total_chunks')::int < 10) as antes_weak,
    -- Ap√≥s re-prepare
    COUNT(*) FILTER (WHERE (metadata->>'total_chunks')::int < 10) as depois_weak
FROM score_item_enrichment_preparation;
```

---

### Melhoria 3: Aumentar Limite de Chunks (F√ÅCIL)

**Problema:** 45.7% (401 preparations) est√£o no limite (20 ou 30), significando que poderiam ter MAIS.

**Solu√ß√£o:** Aumentar limite de 30 ‚Üí 50

```go
// prepare-all/main.go
// Antes:
prepService.PrepareChunks(item.ID, 30, 0.3)

// Depois:
prepService.PrepareChunks(item.ID, 50, 0.3)
```

**Impacto:**
- Preparations com 30 chunks ‚Üí podem chegar a 40-50
- Mais contexto cient√≠fico para enrichment
- Custo quase zero (s√≥ storage)

---

### Melhoria 4: Prioriza√ß√£o Inteligente de Chunks (M√âDIO)

**Problema:** N√£o sabemos QUAIS chunks s√£o selecionados - pode estar pegando chunks ruins.

**Solu√ß√£o:** Ranking multi-crit√©rio

```go
// F√≥rmula de ranking (j√° implementada parcialmente)
score = base_similarity √ó section_weight √ó recency_factor

// Section weights (j√° existe):
- results:     1.10 (+10%)
- discussion:  1.05 (+5%)
- methods:     1.02 (+2%)
- introduction: 1.01 (+1%)

// NOVO - Recency factor:
recency_factor = {
    if year >= 2020: 1.05 (+5% para artigos recentes)
    if year >= 2015: 1.0
    else: 0.95
}

// NOVO - Length bonus:
length_bonus = {
    if word_count >= 200: 1.02 (+2% para chunks substanciais)
    else: 1.0
}
```

**Implementa√ß√£o:**
Modificar `FindTopChunksForScoreItem` para incluir:
- Recency boost
- Length quality filter

---

### Melhoria 5: Metadata Enriquecido (F√ÅCIL)

**Problema:** Metadata atual n√£o tem informa√ß√µes suficientes para QA.

**Solu√ß√£o:** Adicionar campos √∫teis

```go
// Score_item_enrichment_preparation.metadata
{
    "total_chunks": 25,
    "articles_count": 8,
    "avg_similarity": 0.68,
    "min_similarity": 0.45,          // NOVO
    "max_similarity": 0.92,          // NOVO
    "sections_distribution": {...},
    "total_word_count": 5420,        // NOVO
    "avg_chunk_length": 216,         // NOVO
    "recency_stats": {               // NOVO
        "newest_year": 2024,
        "oldest_year": 2010,
        "avg_year": 2018
    },
    "quality_grade": "excellent"     // NOVO (based on chunks + similarity)
}
```

**Uso:**
- QA: identificar preparations ruins antes de enrichment
- Analytics: tracking de qualidade ao longo do tempo

---

### Melhoria 6: Invalida√ß√£o Autom√°tica (CR√çTICO)

**Problema:** Se ScoreItem √© editado, preparation fica DESATUALIZADA (mesma issue dos embeddings).

**Solu√ß√£o:** Hook BeforeUpdate no ScoreItem (similar ao embedding)

```go
// score_item.go - BeforeUpdate
func (si *ScoreItem) BeforeUpdate(tx *gorm.DB) error {
    // ... c√≥digo existente de embedding invalidation

    // NOVO: Invalidar preparation tamb√©m
    if needsReembedding {  // Mesma condi√ß√£o
        tx.Exec(`
            UPDATE score_item_enrichment_preparation
            SET status = 'stale'
            WHERE score_item_id = ?
        `, si.ID)

        // Ou deletar diretamente para for√ßar re-prepare
        tx.Exec(`
            DELETE FROM score_item_enrichment_preparation
            WHERE score_item_id = ?
        `, si.ID)
    }

    return nil
}
```

**Adicionar status 'stale':**
```sql
ALTER TABLE score_item_enrichment_preparation
ALTER COLUMN status TYPE varchar(20);

ALTER TABLE score_item_enrichment_preparation
DROP CONSTRAINT IF EXISTS score_item_enrichment_preparation_status_check;

ALTER TABLE score_item_enrichment_preparation
ADD CONSTRAINT score_item_enrichment_preparation_status_check
CHECK (status IN ('ready','processing','completed','failed','stale'));
```

---

## üöÄ Plano de Implementa√ß√£o

### Fase 1: Quick Wins (1 hora)

#### 1.1. Aumentar limite de chunks (10 min)
```go
// prepare-all/main.go linha 49
prepService.PrepareChunks(item.ID, 50, 0.3)  // 30 ‚Üí 50
```

#### 1.2. Re-prepare items com < 10 chunks (20 min)
Criar comando `re-prepare-weak/main.go`:
```go
// DELETE preparations com < 10 chunks
// Re-executar prepare-all apenas para esses
```

#### 1.3. Adicionar metadata enriquecido (30 min)
Modificar `PrepareChunks` para calcular min/max similarity, word count total, etc.

---

### Fase 2: Threshold Adaptativo (2 horas)

#### 2.1. Implementar tentativas progressivas
```go
func PrepareChunksAdaptive(scoreItemID uuid.UUID) {
    thresholds := []float64{0.3, 0.25, 0.2, 0.15}
    targetChunks := 20

    for _, threshold := range thresholds {
        chunks := FindTopChunks(scoreItemID, 50, threshold)

        if len(chunks) >= targetChunks {
            return savePreparation(chunks[:min(30, len(chunks))])
        }
    }

    // Salvaguarda: retornar o que encontrou
    return savePreparation(chunks)
}
```

#### 2.2. Logging de fallback
Adicionar log quando usa threshold < 0.3:
```
‚ö†Ô∏è  ScoreItem "Albumina": fallback to threshold 0.25 (30 chunks found)
```

---

### Fase 3: Prioriza√ß√£o Avan√ßada (3 horas - OPCIONAL)

#### 3.1. Recency boost
```sql
-- Modificar FindTopChunksForScoreItem
recency_factor = CASE
    WHEN EXTRACT(YEAR FROM a.publish_date) >= 2020 THEN 1.05
    WHEN EXTRACT(YEAR FROM a.publish_date) >= 2015 THEN 1.0
    ELSE 0.95
END
```

#### 3.2. Length quality filter
```sql
-- Filtrar chunks muito curtos (< 50 words)
WHERE COALESCE((ae.chunk_metadata->>'word_count')::int, 0) >= 50
```

---

## üìä Resultados Esperados

### Antes (Atual)
```
Preparations:
  Fracas (< 10 chunks):    376 (42.8%) ‚ùå
  1 chunk apenas:          103 (11.7%) ‚ùå
  Avg chunks:              13.0
  No limite (20/30):       401 (45.7%)
```

### Depois (Projetado)
```
Preparations:
  Fracas (< 10 chunks):    < 50 (< 6%) ‚úÖ
  1 chunk apenas:          0 (0%) ‚úÖ
  Avg chunks:              24-27
  √ìtimas (20-40 chunks):   ~750 (85%+) ‚úÖ
```

---

## üõ†Ô∏è Arquivos a Modificar

### Quick Wins
1. `apps/api/cmd/prepare-all/main.go` - aumentar limite 30‚Üí50
2. `apps/api/cmd/re-prepare-weak/main.go` - NOVO comando
3. `apps/api/internal/services/score_enrichment_preparation_service.go` - metadata enriquecido

### Threshold Adaptativo
4. `apps/api/internal/services/score_enrichment_preparation_service.go` - l√≥gica adaptativa
5. `apps/api/cmd/prepare-all/main.go` - usar m√©todo adaptativo

### Invalida√ß√£o Autom√°tica
6. `apps/api/internal/models/score_item.go` - hook BeforeUpdate
7. `apps/api/database/migrations/` - adicionar status 'stale'

---

## üß™ Verifica√ß√£o

### Ap√≥s Quick Wins
```sql
-- Dever√° mostrar < 50 preparations fracas
SELECT COUNT(*)
FROM score_item_enrichment_preparation
WHERE (metadata->>'total_chunks')::int < 10;
```

### Ap√≥s Threshold Adaptativo
```sql
-- Avg chunks dever√° ser 24-27
SELECT
    ROUND(AVG((metadata->>'total_chunks')::int), 1) as avg_chunks,
    COUNT(*) FILTER (WHERE (metadata->>'total_chunks')::int >= 20) as boas
FROM score_item_enrichment_preparation;
```

---

## üí≠ Considera√ß√µes

### Por que tantas preparations fracas?

1. **ScoreItems muito espec√≠ficos** (ex: "ACTN3 rs1815739")
   - Poucos artigos sobre t√≥picos muito nichados
   - Threshold 0.3 n√£o encontra matches suficientes

2. **ScoreItems demogr√°ficos** (ex: "Hemoglobina - Mulheres p√≥s-menopausa")
   - Embeddings com demografia podem ter reduzido matches
   - Threshold mais baixo ajudaria

3. **Artigos com poucos chunks**
   - Se artigo s√≥ tem 5 chunks total, n√£o d√° para pegar 20
   - Solu√ß√£o: aceitar menos chunks para esses casos

### Trade-offs

| Abordagem | Pr√≥s | Contras |
|-----------|------|---------|
| **Threshold fixo 0.3** | Alta precision | 42.8% fracas |
| **Threshold adaptativo** | Cobertura melhor | Pode incluir chunks menos relevantes |
| **Limite 50 chunks** | Mais contexto | Mais noise potencial |

**Recomenda√ß√£o:** Threshold adaptativo + limite 50 + filtro de qualidade m√≠nima (similarity ‚â• 0.2 absoluto)

---

## üìù Pr√≥ximos Passos Recomendados

### Imediato (FAZER AGORA)
1. ‚úÖ Aumentar limite de 30 ‚Üí 50
2. ‚úÖ Deletar preparations com < 10 chunks
3. ‚úÖ Re-executar prepare-all com threshold adaptativo

### Curto Prazo (1 semana)
4. Implementar threshold adaptativo completo
5. Adicionar invalida√ß√£o autom√°tica via hook
6. Criar analytics dashboard de qualidade de preparation

### M√©dio Prazo (1 m√™s)
7. Recency boost para artigos recentes
8. Length quality filter (chunks < 50 words)
9. A/B testing de strategies de sele√ß√£o

---

## üéØ Objetivo Final

```
‚úÖ 100% preparations com >= 15 chunks
‚úÖ Avg chunks: 25-30
‚úÖ 0% preparations com 1 chunk
‚úÖ Auto-invalida√ß√£o quando ScoreItem muda
‚úÖ Metadata rico para QA e analytics
```

**Enrichment cient√≠fico de alta qualidade para TODOS os ScoreItems!** üöÄ
